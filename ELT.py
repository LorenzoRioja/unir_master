
"""ETL_unir_master_LRO.ipynb

Automatically generated by Colaboratory.

Creamos la conexión a Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""Hacemos los imports"""

import os
import pandas as pd
import requests
import datetime as dt
import xlrd
from bs4 import BeautifulSoup, SoupStrainer

"""Inicializamos variables del proyecto"""

path_datalake = '/content/drive/My Drive/unir_master_datalake/'

path_datadump_cne = path_datalake + 'cne/'
path_datadump_sepe = path_datalake + 'sepe/'
path_datadump_ss = path_datalake + 'ss/'
path_datadump_transformaciones = path_datalake + 'transformaciones/'

years = [14,15,16,17,18,19,20]
months = ['01','02','03','04','05','06','07','08','09','10','11','12']
actual_month = dt.date.today().month

ccaa_list = ['ANDALUCÍA','ARAGÓN','P. DE ASTURIAS','ILLES BALEARS','CANARIAS','CANTABRIA','CASTILLA Y LEÓN','CASTILLA-LA MANCHA',
           'CATALUÑA','COM.VALENCIANA','EXTREMADURA','GALICIA','COM.DE MADRID','REG. DE MURCIA','COM. F. DE NAVARRA','PAÍS VASCO',
           'LA RIOJA','CEUTA','MELILLA','PAIS VASCO','ANDALUCIA','ASTURIAS','ARAGON','CAST.-LA MANCHA','NAVARRA','CMDAD.DE MADRID','CASTILLA-LEON',
           'PRINCIPADO DE AS','CASTILLA Y LEON','COM. VALENCIANA','COM. DE MADRID','REGION DE MURCIA','COM. FORAL DE NC']

"""Creamos la arquitectura de carpetas si no existe"""

if os.path.isdir(path_datalake) is False:
    print('Creating directories in unir_master_datalake')
    os.mkdir(path_datalake)
    os.mkdir(path_datadump_cne)
    os.mkdir(path_datadump_sepe)
    os.mkdir(path_datadump_ss)
    os.mkdir(path_datadump_transformaciones)

"""# CNE

ELT de covid de la fuente CNE
"""

url_cne_data = 'https://cnecovid.isciii.es/covid19/resources/datos_ccaas.csv'
filepath_datadump_cne = path_datadump_cne + 'datos_ccaas.csv'
filepath_cne_transformaciones = path_datadump_transformaciones + 'cne_transform.csv'

"""ELT de CNE"""

data_cne = pd.read_csv(url_cne_data)

data_cne.to_csv(filepath_datadump_cne, index = False)

"""Transformacion de CNE"""

col_cne = ['fecha','ccaa','num_casos']
df_cne = pd.DataFrame(columns = col_cne)

df_cne['fecha'] = data_cne['fecha']
df_cne['ccaa'] = data_cne['ccaa_iso']
df_cne['num_casos'] = data_cne['num_casos']

df_cne.to_csv(filepath_cne_transformaciones, index = False)

"""# SEPE"""

url_path_sepe = 'https://www.sepe.es/SiteSepe/contenidos/que_es_el_sepe/estadisticas/datos_avance/datos/datos_20'
file_extension_xls= '.xls'
filepath_sepe_transformaciones = path_datadump_transformaciones + 'sepe_transform.csv'

"""### ELT de paro de la fuente SEPE"""

for y in years:
    url = url_path_sepe + str(y) + '/'
    file_header_sepe = 'Av_sispe_' + str(y)
    for m in months:
        if (100*y + int(m)) < 2000 + actual_month:
            filepath_datadump = path_datadump_sepe + file_header_sepe + m + file_extension_xls
            r = requests.get(url + file_header_sepe + m + file_extension_xls, allow_redirects=True)
            open(filepath_datadump, 'wb').write(r.content)
            print(url + file_header_sepe + m + file_extension_xls)
            print(filepath_datadump)
            print(file_header_sepe + m + file_extension_xls + ' -> loaded')

# el fichero de enero viene con una extensión .xls0
r = requests.get(url_path_sepe + '20/Av_sispe_2001.xls0', allow_redirects=True)
open(path_datadump_sepe + 'Av_sispe_2001.xls', 'wb').write(r.content)

"""### Transformación de SEPE"""

col_sepe = ['mes','ccaa','dem_ocupados','dem_sin_dispo','dem_otros','paro']
df_sepe = pd.DataFrame(columns = col_sepe)

mes_sepe = []
ccaa_2_sepe = []
ccaa_2_sepe_cod = []
ocupados_6 = []
sin_dispo_8 = []
otros_12 = []
paro_14 = []

for y in years:
    file_header = 'Av_sispe_' + str(y)
    for m in months:
        if (100*y + int(m)) < 2000 + actual_month:
            filepath_datadump = path_datadump_sepe + file_header + m + file_extension_xls
            print(filepath_datadump)
            wb = xlrd.open_workbook(filepath_datadump)
            ws = wb.sheet_by_index(1)
            for r in range(35,54):
                mes_sepe.append('20' + str(y) + m)
                ccaa_2_sepe.append(ws.cell(r,2).value)
                ocupados_6.append(int(ws.cell(r,6).value))
                sin_dispo_8.append(int(ws.cell(r,8).value))
                otros_12.append(int(ws.cell(r,12).value))
                paro_14.append(int(ws.cell(r,14).value))


for com in ccaa_2_sepe:
    ccaa_2_sepe_cod.append(com.
                         replace('CANTABRIA','CB').
                         replace('ANDALUCÍA','AN').
                         replace('ANDALUCIA','AN').
                         replace('ARAGÓN','AR').
                         replace('ARAGON','AR').
                         replace('P. DE ASTURIAS','AS').
                         replace('ASTURIAS','AS').
                         replace('PRINCIPADO DE AS','AS').
                         replace('ILLES BALEARS','IB').
                         replace('CANARIAS','CN').
                         replace('CANTABRIA','CB').
                         replace('CASTILLA Y LEÓN','CL').
                         replace('CASTILLA-LEON','CL').
                         replace('CASTILLA Y LEON','CL').
                         replace('CASTILLA-LA MANCHA','CM').
                         replace('CAST.-LA MANCHA','CM').
                         replace('CATALUÑA','CT').
                         replace('COM.VALENCIANA','VC').
                         replace('COM. VALENCIANA','VC').
                         replace('EXTREMADURA','EX').
                         replace('GALICIA','GA').
                         replace('COM.DE MADRID','MD').
                         replace('CMDAD.DE MADRID','MD').
                         replace('COM. DE MADRID','MD').
                         replace('REG. DE MURCIA','MC').
                         replace('REGION DE MURCIA','MC').                         
                         replace('COM. F. DE NAVARRA','NC').
                         replace('NAVARRA','NC').
                         replace('COM. FORAL DE NC','NC').
                         replace('PAÍS VASCO','PV').
                         replace('PAIS VASCO','PV').
                         replace('LA RIOJA','RI').
                         replace('CEUTA','CE').
                         replace('MELILLA','ML')
    )
     

df_sepe['mes'] = mes_sepe
df_sepe['ccaa'] = ccaa_2_sepe_cod
df_sepe['dem_ocupados'] = ocupados_6
df_sepe['dem_sin_dispo'] = sin_dispo_8
df_sepe['dem_otros'] = otros_12
df_sepe['paro'] = paro_14

df_sepe.to_csv(filepath_sepe_transformaciones, index = False)
print ('Save to ->' + filepath_sepe_transformaciones)

"""# SEGURIDAD SOCIAL"""

filepath_ss_transformaciones = path_datadump_transformaciones + 'ss_transform.csv'

"""### Web Scraping SS

Hacemos el Web Scraping para 2020
"""

file_url_ss_2020 = []
filenames_ss_2020 = []
url_ss_2020 = 'http://www.seg-social.es/wps/portal/wss/internet/EstadisticasPresupuestosEstudios/Estadisticas/EST8/EST11/2851'

page_2020 = requests.get(url_ss_2020)    
data_2020 = page_2020.text
soup_2020 = BeautifulSoup(data_2020)

for link in soup_2020.find_all('a'):
    if 'Afiliados-altas' in (link.get('href')) and '.xls' in (link.get('href')):
        file_url_ss_2020.append(link.get('href'))
        filenames_ss_2020.append(link.get('href').split('/')[6][:39])
        print(link.get('href').split('/')[6][:39])

"""Hacemos el Web Scraping para 2019"""

file_url_ss_2019 = []
filenames_ss_2019 = []
url_ss_2019 = 'http://www.seg-social.es/wps/portal/wss/internet/EstadisticasPresupuestosEstudios/Estadisticas/EST8/EST167/21b04ced-f0f1-4bb9-9662-0437a6f9934e/131573df-9d70-4cda-9b48-703f20d14d9d'

page_2019 = requests.get(url_ss_2019)    
data_2019 = page_2019.text
soup_2019 = BeautifulSoup(data_2019)

for link in soup_2019.find_all('a'):
    if 'Afiliados-altas' in (link.get('href')) and '.xls' in (link.get('href')):
        file_url_ss_2019.append(link.get('href'))
        filenames_ss_2019.append(link.get('href').split('/')[6][:36])
        print(link.get('href').split('/')[6][:36])

"""Hacemos el Web Scraping para 2018"""

file_url_ss_2018 = []
filenames_ss_2018 = []
url_ss_2018 = 'http://www.seg-social.es/wps/portal/wss/internet/EstadisticasPresupuestosEstudios/Estadisticas/EST8/EST167/60acb645-0034-40c7-a978-29721ccd66d2/57d53774-86e9-4d87-8ed9-e432a1911da0'

page_2018 = requests.get(url_ss_2018)    
data_2018 = page_2018.text
soup_2018 = BeautifulSoup(data_2018)

for link in soup_2018.find_all('a'):
    if 'Afiliados-altas' in (link.get('href')) and '.xls' in (link.get('href')):
        file_url_ss_2018.append(link.get('href'))
        filenames_ss_2018.append(link.get('href').split('/')[6][:36])
        print(link.get('href').split('/')[6][:36])

"""Hacemos el Web Scraping para 2017"""

file_url_ss_2017 = []
filenames_ss_2017 = []
url_ss_2017 = 'http://www.seg-social.es/wps/portal/wss/internet/EstadisticasPresupuestosEstudios/Estadisticas/EST8/EST167/3710/3733'

page_2017 = requests.get(url_ss_2017)    
data_2017 = page_2017.text
soup_2017 = BeautifulSoup(data_2017)

for link in soup_2017.find_all('a'):
    if 'Afiliados-altas' in (link.get('href')) and '.xls' in (link.get('href')):
        file_url_ss_2017.append(link.get('href'))
        filenames_ss_2017.append(link.get('href').split('/')[6][:36])
        print(link.get('href').split('/')[6][:36])

"""Hacemos el Web Scraping para 2016"""

file_url_ss_2016 = []
filenames_ss_2016 = []
url_ss_2016 = 'http://www.seg-social.es/wps/portal/wss/internet/EstadisticasPresupuestosEstudios/Estadisticas/EST8/EST167/3575/3576'

page_2016 = requests.get(url_ss_2016)    
data_2016 = page_2016.text
soup_2016 = BeautifulSoup(data_2016)

for link in soup_2016.find_all('a'):
    if 'Afiliados-altas' in (link.get('href')) and '.xls' in (link.get('href')):
        file_url_ss_2016.append(link.get('href'))
        filenames_ss_2016.append(link.get('href').split('/')[6][:36])
        print(link.get('href').split('/')[6][:36])

"""Hacemos el Web Scraping para 2015"""

file_url_ss_2015 = []
filenames_ss_2015 = []
url_ss_2015 = 'http://www.seg-social.es/wps/portal/wss/internet/EstadisticasPresupuestosEstudios/Estadisticas/EST8/EST167/3252/3253'

page_2015 = requests.get(url_ss_2015)    
data_2015 = page_2015.text
soup_2015 = BeautifulSoup(data_2015)

for link in soup_2015.find_all('a'):
    if 'Afiliados-altas' in (link.get('href')) and '.xls' in (link.get('href')):
        file_url_ss_2015.append(link.get('href'))
        filenames_ss_2015.append(link.get('href').split('/')[6][:36])
        print(link.get('href').split('/')[6][:36])

"""Hacemos el Web Scraping para 2014"""

file_url_ss_2014 = []
filenames_ss_2014 = []
url_ss_2014 = 'http://www.seg-social.es/wps/portal/wss/internet/EstadisticasPresupuestosEstudios/Estadisticas/EST8/EST167/3010/3011'

page_2014 = requests.get(url_ss_2014)    
data_2014 = page_2014.text
soup_2014 = BeautifulSoup(data_2014)

for link in soup_2014.find_all('a'):
    if 'Afiliados-altas' in (link.get('href')) and '.xls' in (link.get('href')):
        file_url_ss_2014.append(link.get('href'))
        filenames_ss_2014.append(link.get('href').split('/')[6][:36])
        print(link.get('href').split('/')[6][:36])

"""Unimos las listas de filenames_ss"""

filenames_ss = filenames_ss_2020 + filenames_ss_2019 + filenames_ss_2018 + filenames_ss_2017 + filenames_ss_2016 + filenames_ss_2015 + filenames_ss_2014
file_url_ss_ant_2020 = file_url_ss_2019 + file_url_ss_2018 + file_url_ss_2017 + file_url_ss_2016 + file_url_ss_2015 + file_url_ss_2014

print(filenames_ss)

"""### ELT de los datos de la SS"""

for furl in file_url_ss_2020:
    r = requests.get('http://www.seg-social.es' + furl, allow_redirects=True)
    open(path_datadump_ss + furl.split('/')[6][:39], 'wb').write(r.content)
    print(furl.split('/')[6][:39])

for furl in file_url_ss_ant_2020:
    r = requests.get('http://www.seg-social.es' + furl, allow_redirects=True)
    open(path_datadump_ss + furl.split('/')[6][:36], 'wb').write(r.content)
    print(furl.split('/')[6][:36])

"""### Transformación de SS"""

col_ss = ['mes','ccaa','afiliados_rg','afiliados_agr','afiliados_hog','afiliados_aut','afiliados_mar','afiliados_carb']
df_ss = pd.DataFrame(columns = col_ss)

mes_ss = []
ccaa_0_ss = []
ccaa_0_ss_cod = []
afiliados_rg_4 = []
afiliados_agr_8 = []
afiliados_hog_12 = []
afiliados_aut_4 = []
afiliados_mar_8 = []
afiliados_carb_12 = []

"""Transformación"""

for f in filenames_ss:
    print(path_datadump_ss + f)
    m = f[28:30]
    y = '20' + f[-6:-4]
    wb = xlrd.open_workbook(path_datadump_ss + f)
    ws = wb.sheet_by_index(0)
    for r in range(7,68):
        if ws.cell(r,0).value in ccaa_list:
            mes_ss.append(y + m)
            ccaa_0_ss.append(ws.cell(r,0).value)
            afiliados_rg_4.append(int(ws.cell(r,4).value))
            afiliados_agr_8.append(int(ws.cell(r,8).value))
            afiliados_hog_12.append(int(ws.cell(r,12).value))
    for r in range(79,140):
        if ws.cell(r,0).value in ccaa_list:
            afiliados_aut_4.append(int(ws.cell(r,4).value))
            afiliados_mar_8.append(int(ws.cell(r,8).value) if ws.cell(r,8).value else 0)
            afiliados_carb_12.append(int(ws.cell(r,12).value) if ws.cell(r,12).value else 0)

for com in ccaa_0_ss:
    ccaa_0_ss_cod.append(com.
                         replace('CANTABRIA','CB').
                         replace('ANDALUCÍA','AN').
                         replace('ANDALUCIA','AN').
                         replace('ARAGÓN','AR').
                         replace('ARAGON','AR').
                         replace('P. DE ASTURIAS','AS').
                         replace('ASTURIAS','AS').
                         replace('ILLES BALEARS','IB').
                         replace('CANARIAS','CN').
                         replace('CANTABRIA','CB').
                         replace('CASTILLA Y LEÓN','CL').
                         replace('CASTILLA-LEON','CL').
                         replace('CASTILLA-LA MANCHA','CM').
                         replace('CAST.-LA MANCHA','CM').
                         replace('CATALUÑA','CT').
                         replace('COM.VALENCIANA','VC').
                         replace('EXTREMADURA','EX').
                         replace('GALICIA','GA').
                         replace('COM.DE MADRID','MD').
                         replace('CMDAD.DE MADRID','MD').
                         replace('REG. DE MURCIA','MC').                        
                         replace('COM. F. DE NAVARRA','NC').
                         replace('NAVARRA','NC').
                         replace('PAÍS VASCO','PV').
                         replace('PAIS VASCO','PV').
                         replace('LA RIOJA','RI').
                         replace('CEUTA','CE').
                         replace('MELILLA','ML')
     
        )

df_ss['mes'] = mes_ss
df_ss['ccaa'] = ccaa_0_ss_cod
df_ss['afiliados_rg'] = afiliados_rg_4
df_ss['afiliados_agr'] = afiliados_agr_8
df_ss['afiliados_hog'] = afiliados_hog_12
df_ss['afiliados_aut'] = afiliados_aut_4
df_ss['afiliados_mar'] = afiliados_mar_8
df_ss['afiliados_carb'] = afiliados_carb_12


df_ss.to_csv(filepath_ss_transformaciones, index = False)
print ('Save to ->' + filepath_ss_transformaciones)

"""# CCAA

Se crea el dataframe que relaciona los códigos iso de las CCAA con sus nombres
"""

filepath_ccaa_transformaciones = path_datadump_transformaciones + 'ccaa.csv'

col_ccaa = ['ccaa','nombre_ccaa']
df_ccaa = pd.DataFrame(columns = col_ccaa)

ccaa_ccaa = ['AN','CB','AR','AS','IB','CN','CL','CM','CT','VC','EX','GA','MD','MC','NC','PV','RI','CE','ML']
nombre_ccaa_ccaa = ['Andalucía','Cantabria','Aragón','Asturias','Islas Baleares','Islas Canarias','Castilla y León',
                    'Castilla la Mancha','Cataluña','Comunidad Valenciana','Extremadura','Galicia','Comunidad de Madrid','Murcia','Navarra','País Vasco','La Rioja','Ceuta','Melilla']

df_ccaa['ccaa'] = ccaa_ccaa
df_ccaa['nombre_ccaa'] = nombre_ccaa_ccaa

"""Se exporta el dataframe de ccaa a un fichero csv"""

df_ccaa.to_csv(filepath_ccaa_transformaciones, index = False)
print ('Save to ->' + filepath_ccaa_transformaciones)
